{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecbkcYtfw2gh"
      },
      "source": [
        "# Topics to be covered in this session:\n",
        "\n",
        "1. How to create tensors?\n",
        "2. Two ways of declaring tensors\n",
        "3. Mathematical Operations\n",
        "4. Linear Algebra\n",
        "\n",
        "### Following topics are covered in the optional session titled: 'Advanced Operations with TensorFlow'\n",
        "\n",
        "5. Reshaping and Broadcasting\n",
        "6. Automatic Differentiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tj7ywgI79Dkd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APYMpAAD9Dkx"
      },
      "source": [
        "### 1. Tensors of different ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVmHbryk9Dkz",
        "outputId": "8132fbdd-f55d-4934-d0cf-42845e88b1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (5,) (5,)\n",
            "Shapes: (3, 2) (3, 2)\n",
            "Shapes: (5, 3, 2) (5, 3, 2)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"A vector is a 1-dimensional tensor\"\"\"\n",
        "\n",
        "# Vector in TensorFlow\n",
        "vector_tf = tf.constant([0, 1, 2, 3, 4])\n",
        "\n",
        "# Vector in Numpy\n",
        "vector_np = np.array([0, 1, 2, 3, 4])\n",
        "\n",
        "print(\"Shapes:\", vector_tf.shape, vector_np.shape)\n",
        "\n",
        "\"\"\" A matrix is a 2-dimensional tensor\"\"\"\n",
        "\n",
        "# Matrix in TensorFlow\n",
        "matrix_tf = tf.constant([[0, 1], [2, 3], [4, 5]])\n",
        "\n",
        "# Matrix in Numpy\n",
        "matrix_np = np.array([[0, 1], [2, 3], [4, 5]])\n",
        "\n",
        "print(\"Shapes:\", matrix_tf.shape, matrix_np.shape)\n",
        "\n",
        "\"\"\"3-dimensional tensor\"\"\"\n",
        "\n",
        "# 3-d tensor in TensorFlow\n",
        "t3_tf = tf.constant([[[0., 1.], [2, 3], [4, 5]]]*5)\n",
        "\n",
        "# 3-d matrix in Numpy\n",
        "t3_np = np.array([[[0, 1], [2, 3], [4, 5]]]*5)\n",
        "\n",
        "print(\"Shapes:\", t3_tf.shape, t3_np.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njx5WAfup-Fg",
        "outputId": "7b9ea04b-5bb7-49f3-b5aa-82792e346161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[0. 1.]\n",
            "  [2. 3.]\n",
            "  [4. 5.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [2. 3.]\n",
            "  [4. 5.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [2. 3.]\n",
            "  [4. 5.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [2. 3.]\n",
            "  [4. 5.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [2. 3.]\n",
            "  [4. 5.]]], shape=(5, 3, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(t3_tf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V80AkyWmzbs"
      },
      "source": [
        "##Question##\n",
        "\n",
        "Declare a tensor of shape (2,2,2,2) with random numbers from normal distribution whose mean is 1 and the standard deviation is also 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Nhxgpwmysz",
        "outputId": "30ead898-8dde-4c1e-8c62-0a217555a694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 2, 2, 2)\n",
            "[[[[-1.39571167  1.10926944]\n",
            "   [-0.54813319  1.47196577]]\n",
            "\n",
            "  [[ 1.27201389 -0.07210695]\n",
            "   [ 0.24347222  1.9718711 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.03357491 -0.64092002]\n",
            "   [ 2.42664426 -0.1799867 ]]\n",
            "\n",
            "  [[-0.03167115  1.20403479]\n",
            "   [-1.6560184  -0.59012454]]]]\n",
            "tf.Tensor(\n",
            "[[[[-0.39571167  2.10926944]\n",
            "   [ 0.45186681  2.47196577]]\n",
            "\n",
            "  [[ 2.27201389  0.92789305]\n",
            "   [ 1.24347222  2.9718711 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.03357491  0.35907998]\n",
            "   [ 3.42664426  0.8200133 ]]\n",
            "\n",
            "  [[ 0.96832885  2.20403479]\n",
            "   [-0.6560184   0.40987546]]]], shape=(2, 2, 2, 2), dtype=float64)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# approach 1 - initialize the nd array in Numpy and then use that to initialize the tensor\n",
        "arr = np.random.randn(2,2,2,2) # returns random numbers from standard normal distribution - mean = 0, std = 1\n",
        "print(arr.shape)\n",
        "print(arr)\n",
        "\n",
        "arr = arr + 1 # adding 1 makes the random numbers from normal distribtuion which has mean = 1\n",
        "\n",
        "# to change the standard deviation as well as multiply with the new standard deviation, std = 2.5\n",
        "# arr = 2.5 * arr + 1\n",
        "\n",
        "arr_tf = tf.constant(arr)\n",
        "print(arr_tf)\n",
        "\n",
        "print(type(arr_tf.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-rxAx15os1C",
        "outputId": "91f9b587-3098-4856-e6b2-43f5a9c2cc99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 2, 2, 2)\n",
            "[[[[ 0.6900752   2.8526578 ]\n",
            "   [ 0.33727247  2.6119318 ]]\n",
            "\n",
            "  [[ 0.30329943  0.67686474]\n",
            "   [ 2.3247914   0.6578677 ]]]\n",
            "\n",
            "\n",
            " [[[-0.47878122  0.65095985]\n",
            "   [ 0.0449633   0.7241368 ]]\n",
            "\n",
            "  [[ 1.7490187   1.8995798 ]\n",
            "   [-0.12209892  1.1263208 ]]]]\n"
          ]
        }
      ],
      "source": [
        "# approach 2 - using random number genrating functions from TensorFlow\n",
        "arr_tf = tf.random.normal((2,2,2,2), mean=1, stddev=1, name=\"my_tensor\")\n",
        "print(arr_tf.shape)\n",
        "print(arr_tf.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZOY4Cka9DlI"
      },
      "source": [
        "### 2. Two ways of declaring tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DojUSo7p9DlK"
      },
      "outputs": [],
      "source": [
        "\"\"\"Two types of tensors: tf.constant & tf.Variable\"\"\"\n",
        "const_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "var_tensor = tf.Variable([[1, 2, 3], [4, 5, 6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnAtZypD9DlW",
        "outputId": "a42716b4-65cd-433e-fa9d-4cbb300e3893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Int32 tensor: <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
            "array([[1, 2, 3],\n",
            "       [4, 5, 6]], dtype=int32)>\n",
            "Float32 tensor: <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "Boolean tensor: <tf.Variable 'Variable:0' shape=(3,) dtype=bool, numpy=array([ True, False, False])>\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Declaring tensors with specific datatypes\"\"\"\n",
        "int32_tensor = tf.Variable([[1, 2, 3], [4, 5, 6]], dtype=tf.int32) # specify int32 datatype\n",
        "float32_tensor = tf.Variable([[1, 2, 3], [4, 5, 6]], dtype=tf.float32) # specify float32 datatype\n",
        "bool_tensor = tf.Variable([True, False, False], dtype=tf.bool) # specify bool datatype.\n",
        "\n",
        "print(\"Int32 tensor:\", int32_tensor)\n",
        "print(\"Float32 tensor:\", float32_tensor)\n",
        "print(\"Boolean tensor:\", bool_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds9LxZwymNZE",
        "outputId": "f5fdb08e-aae4-4d3a-f415-7440d9d55915"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]], dtype=int32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int32_tensor.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohfnXsg9Dlh"
      },
      "source": [
        "#### Note that tf.Variable infers the datatype if it is not specified. Hence the bool tensor could have been declared as\n",
        "#### bool_tensor = tf.Variable([True, False, False])\n",
        "#### and the result would have been same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zas4Grvj9Dlk"
      },
      "source": [
        "### 3. Common mathematical operations on tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfp_4p929Dlm",
        "outputId": "3f5d8c2e-e245-4a4a-9d91-5d3d5dd924e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: <tf.Variable 'Variable:0' shape=(5, 5) dtype=int32, numpy=\n",
            "array([[0, 1, 2, 3, 4],\n",
            "       [0, 1, 2, 3, 4],\n",
            "       [0, 1, 2, 3, 4],\n",
            "       [0, 1, 2, 3, 4],\n",
            "       [0, 1, 2, 3, 4]], dtype=int32)>\n",
            "y: <tf.Variable 'Variable:0' shape=(5, 5) dtype=int32, numpy=\n",
            "array([[5, 6, 7, 8, 9],\n",
            "       [5, 6, 7, 8, 9],\n",
            "       [5, 6, 7, 8, 9],\n",
            "       [5, 6, 7, 8, 9],\n",
            "       [5, 6, 7, 8, 9]], dtype=int32)>\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Let us define two tensors\"\"\"\n",
        "\n",
        "x = tf.Variable([list(range(5))]*5) # 2D tensor of shape (5, 5)\n",
        "y = tf.Variable([list(range(5, 10))]*5) # 2D tensor of shape (5, 5)\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVBPNaJH9Dlx",
        "outputId": "5d723f44-24cf-47ff-b02b-181da5b2b660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z: tf.Tensor(\n",
            "[[ 5  7  9 11 13]\n",
            " [ 5  7  9 11 13]\n",
            " [ 5  7  9 11 13]\n",
            " [ 5  7  9 11 13]\n",
            " [ 5  7  9 11 13]], shape=(5, 5), dtype=int32)\n",
            "w: tf.Tensor(\n",
            "[[ 0  6 14 24 36]\n",
            " [ 0  6 14 24 36]\n",
            " [ 0  6 14 24 36]\n",
            " [ 0  6 14 24 36]\n",
            " [ 0  6 14 24 36]], shape=(5, 5), dtype=int32)\n",
            "v: tf.Tensor(\n",
            "[[       inf 6.         3.5        2.66666667 2.25      ]\n",
            " [       inf 6.         3.5        2.66666667 2.25      ]\n",
            " [       inf 6.         3.5        2.66666667 2.25      ]\n",
            " [       inf 6.         3.5        2.66666667 2.25      ]\n",
            " [       inf 6.         3.5        2.66666667 2.25      ]], shape=(5, 5), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Simple mathematical operations two tensors\"\"\"\n",
        "z = x + y # element-wise addition\n",
        "print(\"z:\", z)\n",
        "\n",
        "w = x * y # element-wise multiplications\n",
        "print(\"w:\", w)\n",
        "\n",
        "v = y / x # element-wise division does not raise exception for division by 0 as TensorFlow supports Inf and NaN types\n",
        "print(\"v:\", v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBTBlviJ9Dl9"
      },
      "source": [
        "#### Alternatively, use TensorFlow functions for the mathematical operations\n",
        "#### z = tf.add(x, y)\n",
        "#### w = tf.multiply(x, y)\n",
        "#### v = tf.divide(y, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5XjMPUP9DmB"
      },
      "source": [
        "#### Note that element-wise operations does not work if tensors have different shapes or cannot be broadcasted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noU1PurS9DmD",
        "outputId": "16fbbf8f-a54e-4950-f106-f0fb9bdd6a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before transpose: <tf.Variable 'Variable:0' shape=(5, 3) dtype=int32, numpy=\n",
            "array([[ 0,  1,  2],\n",
            "       [ 3,  4,  5],\n",
            "       [ 6,  7,  8],\n",
            "       [ 9, 10, 11],\n",
            "       [12, 13, 14]], dtype=int32)>\n",
            "After transpose: tf.Tensor(\n",
            "[[ 0  3  6  9 12]\n",
            " [ 1  4  7 10 13]\n",
            " [ 2  5  8 11 14]], shape=(3, 5), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# transpose of tensors\n",
        "y = tf.Variable([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]) # shape is (5, 3)\n",
        "z = tf.transpose(y) # shape is (3, 5)\n",
        "print(\"Before transpose:\", y)\n",
        "print(\"After transpose:\", z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial tensor:  [[ 2  1]\n",
            " [ 9 12]]\n",
            "Squared tensor =  [[  4   1]\n",
            " [ 81 144]]\n"
          ]
        }
      ],
      "source": [
        "x = tf.random.uniform((2,2), minval= 1, maxval= 20, dtype= tf.int32)\n",
        "print(\"Initial tensor: \", x.numpy())\n",
        "y = tf.multiply(x, x)\n",
        "print(\"Squared tensor = \", y.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yPc7969DmN"
      },
      "source": [
        "###     \n",
        "### 4. Linear algebra on tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk4_2eaW9DmO",
        "outputId": "559c5b37-81cd-4d85-fabe-8bbd8954f96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z: tf.Tensor(\n",
            "[[ 90 100 110]\n",
            " [240 275 310]\n",
            " [390 450 510]\n",
            " [540 625 710]\n",
            " [690 800 910]], shape=(5, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "x = tf.Variable([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])\n",
        "y = tf.Variable([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]])\n",
        "\n",
        "z = tf.linalg.matmul(x, y) # matrix multiplication between a (5, 5) and a (5, 3) tensor\n",
        "print(\"z:\", z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjCb05rS9DmY"
      },
      "source": [
        "#### Note that tf.linalg.matmul raises exception if tensor shapes are incompatible for matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UV4D5o99Dma",
        "outputId": "867b129c-68a4-4645-f2e1-c58e55dbd776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception raised while performing tensor inverse:\n",
            " Value for attr 'T' of int32 is not in the list of allowed values: double, float, half, complex64, complex128\n",
            "\t; NodeDef: {{node MatrixInverse}}; Op<name=MatrixInverse; signature=input:T -> output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]> [Op:MatrixInverse] name: \n"
          ]
        }
      ],
      "source": [
        "# Matrix inverse\n",
        "try:\n",
        "    x = tf.Variable([[2, 3], [2, 2]])\n",
        "    xinv = tf.linalg.inv(x)\n",
        "    print(\"Inverse of x:\", xinv)\n",
        "except Exception as e:\n",
        "    print(\"Exception raised while performing tensor inverse:\\n\", str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASTXSFfB9Dmi"
      },
      "source": [
        "#### The above exception occured because matrix inverse is allowed only for float datatypes (float16, float 32 etc.). The try-except block\n",
        "#### is purposefully used to demonstrate this behaviour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usp9kOPy9Dmk",
        "outputId": "64aab7f1-c2bf-4d5a-ceb5-6d4d6457cae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inverse of x: tf.Tensor(\n",
            "[[-1.   1.5]\n",
            " [ 1.  -1. ]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Let us try after changing the datatype using tf.cast function\n",
        "x = tf.cast(x, tf.float32)\n",
        "xinv = tf.linalg.inv(x)\n",
        "print(\"Inverse of x:\", xinv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qNRhN0e9Dmt"
      },
      "source": [
        "#### Note that if the matrix is not invertible tf.linalg.inv will raise an exception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YLuuHG79Dmu",
        "outputId": "a00101ca-7889-4c25-d5e8-ee79e4a4cc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eigen values: tf.Tensor([-1.0000002 -0.9999995  8.000001 ], shape=(3,), dtype=float32)\n",
            "Eigen vectors: tf.Tensor(\n",
            "[[-0.74535596  0.          0.66666675]\n",
            " [ 0.2981424  -0.8944272   0.33333328]\n",
            " [ 0.59628487  0.4472136   0.6666666 ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Eigen value decomposition\n",
        "x = tf.Variable([[3, 2, 4], [2, 0, 2], [4, 2, 3]], dtype=tf.float32) # raises exception if datatype is not floatX\n",
        "eigen_values, eigen_vectors = tf.linalg.eigh(x)\n",
        "print(\"Eigen values:\", eigen_values)\n",
        "print(\"Eigen vectors:\", eigen_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL6qCRPsSsS"
      },
      "source": [
        "##Question##\n",
        "\n",
        "Solve the following system of linear equations using TensorFlow:\n",
        "\n",
        "x + y + z + w = 13\n",
        "\n",
        "2x + 3y − w = −1\n",
        "\n",
        "−3x + 4y + z + 2w = 10\n",
        "\n",
        "x + 2y − z + w = 1\n",
        "\n",
        "Ans: x = 2, y = 0, z = 6 , w = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIPAK-Swsx6s",
        "outputId": "c81ee54f-7963-4c30-84fa-ceec961c70cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coeff: <tf.Variable 'Variable:0' shape=(4, 4) dtype=float32, numpy=\n",
            "array([[ 1.,  1.,  1.,  1.],\n",
            "       [ 2.,  3.,  0., -1.],\n",
            "       [-3.,  4.,  1.,  2.],\n",
            "       [ 1.,  2., -1.,  1.]], dtype=float32)>\n",
            "y: <tf.Variable 'Variable:0' shape=(4, 1) dtype=float32, numpy=\n",
            "array([[13.],\n",
            "       [-1.],\n",
            "       [10.],\n",
            "       [ 1.]], dtype=float32)>\n",
            "Inverse of coeff: tf.Tensor(\n",
            "[[ 2.77777791e-01  5.55555224e-02 -1.66666672e-01  1.11111104e-01]\n",
            " [-7.40740746e-02  1.85185164e-01  1.11111112e-01  3.70370336e-02]\n",
            " [ 4.62962925e-01  9.25926045e-02  5.55555597e-02 -4.81481493e-01]\n",
            " [ 3.33333343e-01 -3.33333343e-01 -7.45058060e-09  3.33333343e-01]], shape=(4, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[2.0000000e+00]\n",
            " [1.8626451e-08]\n",
            " [5.9999990e+00]\n",
            " [5.0000005e+00]], shape=(4, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "coeff = tf.Variable([[1,1,1,1], [2,3,0,-1], [-3,4,1,2], [1,2,-1,1]], dtype=tf.float32) # W\n",
        "print(\"Coeff:\", coeff)\n",
        "\n",
        "y = tf.Variable([[13], [-1], [10], [1]], dtype=tf.float32)\n",
        "print(\"y:\", y)\n",
        "\n",
        "# x = inverse of coeff X y\n",
        "\n",
        "inv_coeff = tf.linalg.inv(coeff)\n",
        "print(\"Inverse of coeff:\", inv_coeff)\n",
        "\n",
        "x_solution = tf.matmul(inv_coeff, y)\n",
        "print(x_solution)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The weights and the bias term of a trained model logistic regression model are given below. \n",
        "\n",
        "w1 = 0.5, w2 = 1 , w3 = -1.2 \n",
        "\n",
        "b = 0.01\n",
        "\n",
        "The features of a certain data point are given below.\n",
        "\n",
        "​x1 = 0.2, x2 = 1, x3 = 0.5\n",
        "\n",
        "Using TensorFlow, find the probability of the data point belonging to the positive class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w: <tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[ 0.5],\n",
            "       [ 1. ],\n",
            "       [-1.2]], dtype=float32)>\n",
            "x: <tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[0.2],\n",
            "       [1. ],\n",
            "       [0.5]], dtype=float32)>\n",
            "b: <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.01], dtype=float32)>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.62480646]], dtype=float32)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# z = w1.x1 + w2.x2 + w3.x3 + b\n",
        "w = tf.Variable([[0.5], [1], [-1.2]], dtype=tf.float32)\n",
        "x = tf.Variable([[0.2], [1], [0.5]], dtype=tf.float32)\n",
        "b = tf.Variable([0.01], dtype=tf.float32)\n",
        "\n",
        "print(\"w:\", w)\n",
        "print(\"x:\", x)\n",
        "print(\"b:\", b)\n",
        "\n",
        "z = tf.matmul(tf.transpose(w), x) + b\n",
        "\n",
        "z.numpy()\n",
        "\n",
        "# sigmoid function\n",
        "\n",
        "sigmoid_output = 1 / (1 + tf.exp(-z))\n",
        "sigmoid_output.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTPCQ_QKvvQK"
      },
      "source": [
        "####**The following topics have been covered in the optional session : 'Advanced Operations with Tensorflow.'**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY2K1HrG9Dm6"
      },
      "source": [
        "### 5. Reshaping and Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8DqitCM9Dm8"
      },
      "source": [
        "#### 5.1. Reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4w_-62t9Dm-",
        "outputId": "439c2b8a-87cc-4dc2-aa13-c3b168a4a2fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial tensor: <tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[-3.,  2.,  4.],\n",
            "       [ 2.,  0., -2.],\n",
            "       [ 5.,  2.,  3.]], dtype=float32)>\n",
            "Reshaped tensor: tf.Tensor(\n",
            "[[-3.]\n",
            " [ 2.]\n",
            " [ 4.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [-2.]\n",
            " [ 5.]\n",
            " [ 2.]\n",
            " [ 3.]], shape=(9, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Reshaping changes the dimensions or axes and assigns the cell values in proper locations in the new tensor\n",
        "x = tf.Variable([[-3, 2, 4], [2, 0, -2], [5, 2, 3]], dtype=tf.float32)\n",
        "print(\"Initial tensor:\", x)\n",
        "x_reshaped = tf.reshape(x, shape=(9, 1)) # a (3, 3) tensor can be reshaped to (9, 1) amd (1, 9) tensors only\n",
        "print(\"Reshaped tensor:\", x_reshaped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmNExRTM9DnH",
        "outputId": "54180358-3a7b-418f-ff93-7eeed6f177da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception raised while reshaping:\n",
            " {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 9 values, but the requested shape has 12 [Op:Reshape]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-11 03:44:13.892696: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Input to reshape is a tensor with 9 values, but the requested shape has 12\n"
          ]
        }
      ],
      "source": [
        "# tf.reshape raises exception if the new shape is incompatible\n",
        "try:\n",
        "    x_reshape = tf.reshape(x, shape=(3, 4))\n",
        "except Exception as e:\n",
        "    print(\"Exception raised while reshaping:\\n\", str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxFN2uRe9DnQ"
      },
      "source": [
        "#### 5.2. Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an6USxre9DnS"
      },
      "source": [
        "##### Mathematical operations on tensors requires shape compatibility otherwise exception is raised. However, broadcasting can resolve shape incompatibilities in few situations. Let us see an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TmTYx0U9DnT",
        "outputId": "f1ba2644-9720-4329-99dc-d583979d3e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of x: (3, 3)\n",
            "Shape of k: (1,)\n",
            "Shape of y: tf.Tensor(\n",
            "[[6.2999997 4.2       8.4      ]\n",
            " [4.2       0.        4.2      ]\n",
            " [8.4       4.2       6.2999997]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable([[3, 2, 4], [2, 0, 2], [4, 2, 3]], dtype=tf.float32)\n",
        "k = tf.Variable([2.1])\n",
        "\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of k:\", k.shape)\n",
        "\n",
        "# element-wise multiplication by broadcasting which repeats the only element in k along both the axes\n",
        "# to resolve the shape imcompatibility\n",
        "y = x * k\n",
        "print(\"Shape of y:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqGTr6_Z9Dnc",
        "outputId": "6a095b46-9a18-45fa-e806-6dbe6faa3a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y: tf.Tensor(\n",
            "[[ 6.2999997  6.        -5.6      ]\n",
            " [ 4.2        0.        -2.8      ]\n",
            " [ 8.4        6.        -4.2      ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Let us see another example\n",
        "k = tf.Variable([2.1, 3.0, -1.4])\n",
        "\n",
        "# in this case broadcasting repeats [2.1, 3.0, -1.4] three times along the row to make the shapes compatible\n",
        "y = x * k\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo1EztuT9Dnn",
        "outputId": "f050e87f-7015-4db1-9102-8a56943141d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y: tf.Tensor(\n",
            "[[[ 6.2999997  6.        -5.6      ]\n",
            "  [ 2.2        0.        -2.2      ]\n",
            "  [ 2.68       4.2       -0.09     ]]\n",
            "\n",
            " [[ 0.        -6.        -1.4      ]\n",
            "  [ 4.4        0.        -2.2      ]\n",
            "  [ 4.02      -4.2       -0.09     ]]], shape=(2, 3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Broadcasting of rank 2 tensor for multiplying with rank 3 tensor\n",
        "\n",
        "# Rank 2 tensor to be broadcasted\n",
        "k = tf.Variable([[2.1, 3.0, -1.4], [1.1, 3.2, -1.1], [0.67, 2.1, -0.03]])\n",
        "\n",
        "# Rank 3 tensor\n",
        "x = tf.Variable([[[3, 2, 4],\n",
        "                  [2, 0, 2],\n",
        "                  [4, 2, 3]],\n",
        "                 [[0, -2, 1],\n",
        "                  [4, 0, 2],\n",
        "                  [6, -2, 3]]\n",
        "                 ], dtype=tf.float32)\n",
        "\n",
        "# Here shape of x is (2, 3, 3) and that of k is (3, 3). Hence broadcasting will add a new axes and repeat k along it.\n",
        "y = x * k\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bn2apUB9Dnz",
        "outputId": "a5983856-43b4-4b59-df2a-1355864d73da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Old shape: (3, 3)\n",
            "New shape: (1, 3, 3)\n",
            "y: tf.Tensor(\n",
            "[[[ 6.2999997  6.        -5.6      ]\n",
            "  [ 2.2        0.        -2.2      ]\n",
            "  [ 2.68       4.2       -0.09     ]]\n",
            "\n",
            " [[ 0.        -6.        -1.4      ]\n",
            "  [ 4.4        0.        -2.2      ]\n",
            "  [ 4.02      -4.2       -0.09     ]]], shape=(2, 3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Alternatively, we can add the new dimension before multiplying\n",
        "print(\"Old shape:\", k.shape)\n",
        "k = tf.expand_dims(k, axis=0) # insert a new axis along the first dimension to create a rank 3 tensor\n",
        "print(\"New shape:\", k.shape)\n",
        "\n",
        "y = x * k\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTS7x13G9Dn7"
      },
      "source": [
        "### 6. Automatic Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8bcZug9Dn9"
      },
      "source": [
        "#### Gradients or partial derivatives are useful for training linear models and neural networks using gradient-based optimization\n",
        "#### TensorFlow's tf.GradientTape records computations and computes gradients in reverse-mode differentiation.\n",
        "#### Let us see how it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E00VcTQN9Dn-"
      },
      "source": [
        "####  \n",
        "#### 6.1 How to use tf.GradientTape?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8zWxrBO9DoA",
        "outputId": "55c47178-dce5-4080-d710-24d670ab6ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient dy_dx: tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# declare tensor for with respect to which gradient is required\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# using tf.GradientTape context to perform computations and record them in tape\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 3.0 * tf.math.log(x)\n",
        "\n",
        "# compute gradients\n",
        "dy_dx = tape.gradient(y, x) # for y = log(x), dy/dx = 1/x\n",
        "print(\"Gradient dy_dx:\", dy_dx) # alternately doing dy_dx.numpy() returns the result as a numpy array which in this case is a single value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Elo0THg9DoI",
        "outputId": "0a84fc55-e40c-44ed-d079-d4c8b360412c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dr_dx: 6.0\n",
            "dr_dy: 8.0\n"
          ]
        }
      ],
      "source": [
        "# for multi-variate functions, gradients are partial derivatives\n",
        "x = tf.Variable(3.0)\n",
        "y = tf.Variable(4.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    r = x**2 + y**2\n",
        "\n",
        "dr_dx, dr_dy = tape.gradient(r, [x, y]) # the first argument is the target function and the second one is a list of variables\n",
        "print(\"dr_dx:\", dr_dx.numpy()) # ∂r/∂x = 2x\n",
        "print(\"dr_dy:\", dr_dy.numpy()) # ∂r/∂y = 2y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQgEyIT79DoQ",
        "outputId": "a6277656-2333-4306-e278-cb4455f2e1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dr_dx: 108.0\n"
          ]
        }
      ],
      "source": [
        "# tf.GradientTape supports the Chain Rule of Differentiation as well\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x ** 2 # y is a function of x\n",
        "    r = y ** 2 # r is a function of y\n",
        "\n",
        "dr_dx = tape.gradient(r, x) # Chain rule is applied to compute dr_dx as r is a function of x through y\n",
        "print(\"dr_dx:\", dr_dx.numpy()) # dr/dx = dr/dy × dy/dx = 2y × 2x = 2(x²) × 2x = 4x³"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7I5bvD69DoZ"
      },
      "source": [
        "#### Note that the intermediate variable 'y' is released outside the context of tf.GradientTape. To compute gradient dr/dy, tf.GradientTape\n",
        "#### needs to be persistent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1AKwufZ9Dod",
        "outputId": "9f7fc9ed-097a-44d8-a792-d3b8cd75d3b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dr_dx: 108.0\n",
            "dr_dy: 18.0\n"
          ]
        }
      ],
      "source": [
        "# Persistent tf.GradientTape\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    y = x ** 2\n",
        "    r = y ** 2\n",
        "\n",
        "dr_dx = tape.gradient(r, x)\n",
        "dr_dy = tape.gradient(r, y)\n",
        "\n",
        "print(\"dr_dx:\", dr_dx.numpy())\n",
        "print(\"dr_dy:\", dr_dy.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn26EzYT9Dom"
      },
      "source": [
        "####  \n",
        "#### 6.2 How to use tf.GradientTape for model training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2rTeP2dh9Dor"
      },
      "outputs": [],
      "source": [
        "# Let us see this in action in the context of Logistic Regression\n",
        "\n",
        "# Points to note:\n",
        "# 1. For logistic regression, the probabilty P(y=1|X) = 1/[1+exp{-(WX+b)}]; where W & b are weights and bias of the model\n",
        "# 2. The loss function is L = -ylog[P(y=1|X)] - (1-y)log[1-P(y=1|X)] otherwise known as binary log loss.\n",
        "# 3. For training the model using Stochastic Gradient Descent, we need to compute ∂L/∂W and ∂L/∂b.\n",
        "\n",
        "# Let us see how we can compute the gradients using tf.GradientTape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "i_qnWPka9Doz"
      },
      "outputs": [],
      "source": [
        "# declare weights and bias of the model\n",
        "num_features = 10 # the model has 10 features\n",
        "W = tf.Variable(tf.random.normal(shape=(10, ))) # wrapping the random numbers with tf.Variable to enable gradients on W\n",
        "b = tf.Variable(tf.random.normal(shape=(1, )))  # wrapping the random numbers with tf.Variable to enable gradients on b\n",
        "\n",
        "# let us initialize a training samples\n",
        "num_samples = 100\n",
        "\n",
        "# generate training samples randomly and wrap them up in tf.constant to disable gradient computation on samples\n",
        "X = tf.constant(tf.random.uniform(shape=(100, 10)))\n",
        "y = tf.constant(tf.cast(tf.greater(tf.random.uniform(shape=(100,)), 0.80), dtype=tf.float32)) # target must be 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCgO3mxn9Do8",
        "outputId": "127deb86-ba35-4e4a-b3d6-bb66f1cbab90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dloss_dW: [0.37542677 0.3219131  0.3283468  0.33053848 0.34031636 0.3431642\n",
            " 0.29418945 0.3443465  0.32951257 0.38811758]\n",
            "dloss_db: [0.69381094]\n"
          ]
        }
      ],
      "source": [
        "# compute gradients\n",
        "with tf.GradientTape() as tape:\n",
        "    log_odds = tf.reduce_sum(W * X, axis=1) + b\n",
        "    # tf.reduce_sum(W * X, axis=1) results in a (1, ) vector to which b is added\n",
        "\n",
        "    probas = tf.sigmoid(log_odds) # using sigmoid function available in TensorFlow\n",
        "\n",
        "    loss = tf.reduce_mean(-y*tf.math.log(probas) -(1.-y)*tf.math.log(1.-probas))\n",
        "\n",
        "[dloss_dW, dloss_db]  = tape.gradient(loss, [W, b])\n",
        "\n",
        "print(\"dloss_dW:\", dloss_dW.numpy())\n",
        "print(\"dloss_db:\", dloss_db.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgAizW9v9DpE"
      },
      "source": [
        "####  \n",
        "#### 6.3 How to disable gradient computation for selected variables?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpaB-VGZ9DpF",
        "outputId": "6b76a96f-b923-48f3-a384-7ffb5eeeae7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dr_dx: 6.0\n",
            "Error occurred during gradient computation:\n",
            " 'NoneType' object has no attribute 'numpy'\n"
          ]
        }
      ],
      "source": [
        "# let us use an earlier example to show how to disable gradient computation\n",
        "# for multi-variate functions, gradients are partial derivatives\n",
        "x = tf.Variable(3.0, trainable=True)  # by default, trainable=True so we did npt mention it earlier\n",
        "y = tf.Variable(4.0, trainable=False) # trainable=False signals tf.GradientTape to stop tracking the variable\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    r = x**2 + y**2\n",
        "\n",
        "try:\n",
        "    dr_dx, dr_dy = tape.gradient(r, [x, y])\n",
        "    print(\"dr_dx:\", dr_dx.numpy())\n",
        "    print(\"dr_dy:\", dr_dy.numpy()) # dr_dy is None hence this line would raise an exception\n",
        "except Exception as e:\n",
        "    print(\"Error occurred during gradient computation:\\n\", str(e))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
