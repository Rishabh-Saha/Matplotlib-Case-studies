{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642cd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93d14016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = \"Sumit is an adjunct faculty at Upgrad.\"\n",
    "\n",
    "processed_doc = model(doc) #proces input and perform NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d41570",
   "metadata": {},
   "source": [
    "Since a named entity is a noun, let us see what information we get from POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf6ecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sumit  --  NOUN\n",
      "is  --  AUX\n",
      "an  --  DET\n",
      "adjunct  --  ADJ\n",
      "faculty  --  NOUN\n",
      "at  --  ADP\n",
      "Upgrad  --  PROPN\n",
      ".  --  PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in processed_doc:\n",
    "    print(token.text, \" -- \", token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf90ee4",
   "metadata": {},
   "source": [
    "So we see that the POD tags for named entitiies are correctly identitfied. Let us see what the output of NER system in spacy to understand the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7085e54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upgrad  --  31  --  37  --  ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in processed_doc.ents:\n",
    "    print(ent.text, \" -- \", ent.start_char, \" -- \", ent.end_char, \" -- \", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4efc8f9",
   "metadata": {},
   "source": [
    "Okay, so we did find some named entities, but clearly we missed the faculty name. May be because the model doesn't recognize Sumit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab540c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2  = \"Dr. Sumit is an adjunct faculty at Upgrad\"\n",
    "processed_doc2 = model(doc2) #proces input and perform NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9a8e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.  --  PROPN\n",
      "Sumit  --  PROPN\n",
      "is  --  AUX\n",
      "an  --  DET\n",
      "adjunct  --  ADJ\n",
      "faculty  --  NOUN\n",
      "at  --  ADP\n",
      "Upgrad  --  PROPN\n"
     ]
    }
   ],
   "source": [
    "for token in processed_doc2:\n",
    "    print(token.text, \" -- \", token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f758bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sumit  --  4  --  9  --  PERSON\n",
      "Upgrad  --  35  --  41  --  ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in processed_doc2.ents:\n",
    "    print(ent.text, \" -- \", ent.start_char, \" -- \", ent.end_char, \" -- \", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c534682",
   "metadata": {},
   "source": [
    "It was able to correct tag Sumit, now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66d02fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = \"Statue of Liberty is situated in New York, USA.\"\n",
    "processed_doc3 = model(doc3) #proces input and perform NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbc3941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statue  --  PROPN\n",
      "of  --  ADP\n",
      "Liberty  --  PROPN\n",
      "is  --  AUX\n",
      "situated  --  VERB\n",
      "in  --  ADP\n",
      "New  --  PROPN\n",
      "York  --  PROPN\n",
      ",  --  PUNCT\n",
      "USA  --  PROPN\n",
      ".  --  PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in processed_doc3:\n",
    "    print(token.text, \" -- \", token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "022e5974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York  --  33  --  41  --  GPE\n",
      "USA  --  43  --  46  --  GPE\n"
     ]
    }
   ],
   "source": [
    "for ent in processed_doc3.ents:\n",
    "    print(ent.text, \" -- \", ent.start_char, \" -- \", ent.end_char, \" -- \", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ed130",
   "metadata": {},
   "source": [
    "The system did not recognize \"Statue of Liberty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99768649",
   "metadata": {},
   "source": [
    "Let us see the output of NER at token level illustrating the IOB format discussed in lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6c7a0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statue  --  O  --  \n",
      "of  --  O  --  \n",
      "Liberty  --  O  --  \n",
      "is  --  O  --  \n",
      "situated  --  O  --  \n",
      "in  --  O  --  \n",
      "New  --  B  --  GPE\n",
      "York  --  I  --  GPE\n",
      ",  --  O  --  \n",
      "USA  --  B  --  GPE\n",
      ".  --  O  --  \n"
     ]
    }
   ],
   "source": [
    "for token in processed_doc3:\n",
    "    print(token.text, \" -- \", token.ent_iob_, \" -- \", token.ent_type_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845f304",
   "metadata": {},
   "source": [
    "- You can use spacy's NER model to identify named entities in input text.\n",
    "- You also studied some cases where the model is not able to correctly identify all the entities invovled.\n",
    "- There are various situations where systems make errors and depending on the appliation and the severity and types of errors, follow up corrective measures can be employed (manual validation, discarding erroneous outouts, using heuristics, etc.)\n",
    "\n",
    "Let us now consider one practical application of NER systems -- Anonymization of data and redacting personally indentifying information.\n",
    "\n",
    "- In many scenarios, we want to withheld sensitive information such as names of persons in various confidential information.\n",
    "- We can use NER methods to automatically identify PERSONS in text and remove PERSON names from text.\n",
    "\n",
    "Let us see how it can be done with what we have learnt till now. We take an example email from Enron e-mail dataset for ilustration in this demo.\n",
    "\n",
    "- E-mail source: http://www.enron-mail.com/email/lay-k/elizabeth/Christmas_in_Aspen_4.html\n",
    "\n",
    "- Complete Enron data: http://www.enron-mail.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abbfc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = ('Dear Family, Jose Luis and I have changed our dates, we are '\n",
    "         'going to come to Aspen on the 23rd of December and leave on the '\n",
    "         '30th of December. We would like to stay in the front bedroom of '\n",
    "         'the Aspen Cottage so that Mark, Natalie and Zachary can stay in '\n",
    "         'the guest cottage. Please let me know if there are any problems '\n",
    "         'with this. If I do not hear anything, I will assume this is all '\n",
    "         'o.k. with you.'\n",
    "         'Love, Liz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1062b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_email = model(email) #proces input and perform NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28c693f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- After Anonymization --\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dear Family, ********* and I have changed our dates, we are going to come to Aspen on the 23rd of December and leave on the 30th of December. We would like to stay in the front bedroom of the Aspen Cottage so that ****, ******* and ******* can stay in the guest cottage. Please let me know if there are any problems with this. If I do not hear anything, I will assume this is all o.k. with you.Love, ***'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anoymized_email = list(email) # intialize data structure to store anonymized email\n",
    "\n",
    "for ent in processed_email.ents:\n",
    "    if ent.label_ == \"PERSON\":\n",
    "        for char_pos in range(ent.start_char, ent.end_char):\n",
    "            anoymized_email[char_pos] = \"*\"\n",
    "\n",
    "print(\"\\n\\n-- After Anonymization --\\n\")\n",
    "\"\".join(anoymized_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46022627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
